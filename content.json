{"posts":[{"title":"锁分析","text":"synchronized 实现原理 synchronized是jvm层面的一种锁,如果是多个jvm则只能在一个jvm中生效 它能保证有序性、可见、原子性 synchronized可以加在方法上 可以是一个代码块，wait/notify也以来monitor对象 这就是为什么要用在同步中的原因 synchronized 最终锁住的是一个对象的monitor。java是编译成为class文件 jvm拿到这个class文件后可以得到要执行的jvm指令，他会把这些指令根据c++代码解析后翻译成为机器码 交给操作系统去执行。 在jvm底层操作jvm指令的源码发现 其实monitor是有一个数据结构的 比如owner 存放的是目前占有锁的线程 EntryList存放的后续来竞争锁的线程 WaitSet 是存放之前获取过锁，但是在WAEIING状态的线程的 在1.5之前他是直接在操作系统层面加锁，所以比较重，在1.6之后可以通过锁升级机制来让锁的性能提高 大概就是可以从无锁、偏向锁、轻量级锁到最后的重量级锁偏向锁就是存在同步但无竞争的情况 比如spring的源码，它里面有一些方法加了同步 但是基本是没有竞争的 那这样的话每次直接判断一下owner中的线程是不是同一个就可以了假设存在少量的几个竞争 那么就会升级成为轻量级锁，轻量级锁他是使用了cas机制，没有获取到锁不会挂起等待，所以就不涉及到cpu调度、线程切换这些比较重的操作，他会一直空轮训自适应自旋 但是这样会耗费cpu资源，所以一旦判断自旋超过多少次，就会觉得线程竞争很厉害，就转换为重量级锁 CAS cas 是比较和交换的意思 是乐观锁的一种实现 可以解决并发问题 它主要实现原理是这样的 有一个主存中的最终结果值 他是被valitile修饰的 还有每一个线程进来后会有一个拿到的值 以及我们要修改的值比如 两个线程并发了 第一个线程拿到是50 第二个线程拿到的也是50 要修改成60在修改成60的时候会把当前拿到的值跟内存中的结果值比较一下 如果一样，才修改成功那么此时这个场景就是a线程拿到50 进行修改 判断50和内存中的50一致 修改成功 内存中值变为60b线程拿到的也是50 进行修改 判断50和当前内存值60 不一致 修改失败 这样就使用cas解决了并发问题但是cas会有两个问题 : 原子性问题和ABA问题原子性问题：判断和修改是两步操作 看底层是使用的lock实现 所以解决原子性问题ABA问题： 假设有三个线程 a,b,c 并发了a线程要把100变为50 b线程也要把100变为50 c线程要把50变为100假设此时a线程 成功执行了 b线程刚执行完和a拿到100这个步骤，阻塞了；此时c线程执行50变100操作成功，也就在此时b线程恢复了 又把100 变成了50 ；这就出现了问题如果要解决的话 需要加一个版本号 更新的时候把版本号更新+1 且判断条件加上版本判断 LongAdder 和 AtomicIntergerAtomicInterger 实现了cas操作LongAdder 是优化后的cas 原理是把数据分段后作cas++ 会根据来的线程多少动态的扩缩数据分段 最后再做累加 分多少段其实理论上性能就提高多少倍threadLocal也能解决 多个线程操作同一变量的问题 分布式锁 多个jvm的时候使用分布式锁 有多个实现版本 基于mysql的 redis的 zookeeper的 分布式锁使用最基础版本的redis的话 需要注意以下几点（1）在设置key的时候要把value设置为能标识当前线程的值（2）且设置一个过期时间，并且使用的是setnx原子操作（3）释放锁要写到finally里面 释放锁的时候要判断是当前线程持有的锁才释放 避免释放掉其他线程的锁 且这两步要是一个原子操作 使用lua脚本来实现（4）要搞一个守护线程，假设锁内业务逻辑没有执行完 要续过期时间 基于以上问题 redsi帮助我们封装了一个redisson客户端 帮助我们封装了以上操作 但是如果我们使用的是redis集群，那么会有一个问题 主从同步场景的时候 如果刚给master上锁成功 master给slave同步数据的时候挂掉了，那么此时再获取锁的时候，在从节点是获取不到锁的，因为redis的模型是AP,只能保证可用性和分区容错性，保证不了一致性 所以此时应该考虑使用redlock去完成分布式锁的添加，但是网上有redlock的问题，所以做分布式锁还是应该优先考虑zookeeper 如果是在删除锁的时候没有用lua脚本也是会有问题的：比如判断是否是同一线程持有的锁已经通过了 a线程此时开始阻塞 刚好这时候通过过期时间过期了锁，那么线程b拿到锁，此时a线程开始执行 就会把线程b的锁释放掉 为什么要选择zookeeper 因为zookeeper是基于CP模型的数据模型，zab来保证一致性问题，所以会导致zookerper比redis性能低，但是我们的场景又是高并发下的分布式锁问题， 如果对于并发出现的问题不能容忍，那么应该优先选用zookeeper，并且redlock 需要至少5个节点 从效率上说其实也不快了 牵扯到的一个秒杀情况下使用分布式锁的性能问题 其实还是分段思想，将库存分布在不同的锁中，那么性能会提示很多 可以解决缓存和数据库双写不一致的问题（市面上有延时双删、内存队列，优化可以使用读写锁） AQS可重入锁 锁的一个关键就是 有并发 并且有竞争 公平锁判断state为0的时候 不能直接cas获取锁 因为是公平锁，此时可能有很多线程已经在排队了 其它线程入队时候 他要自旋2次，自旋两次的时候会尝试获取锁 比如有三个线程 此时第一个已经释放了，第二个就会拿到锁 且变为thread==null的head节点，但是此时第三个线程来了 在入队过程中他要自旋，那么此时就会判断：来询问能否获取到锁的线程，是不是除去thread==null那个节点的第二个节点 如果不是thread==null的那个节点的线程 肯定不能获取锁 第二个线程来入队的时候会进行自旋 自旋的时候会判断：锁是自由状态 且去竞争的线程是thread==null后面的节点的线程才有资格进行cas获取锁 可重入的时候也会判断持有锁的线程永远不在队列中 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); 第一种：队列没有初始化 h!=t 返回false 返回false 意味着可以尝试cas获取锁第二种：如果队列初始化了，初始化后 分两种情况 1.1: 如果队列中的元素比较多 那么h!t 返回true 返回true 要分为两种情况 1.1.1 如果(s = h.next) == null 返回true 说明有两个元素 后面的 s.thread != Thread.currentThread() 就不判断了 那么肯定要排队 1.1.2 如果(s = h.next) == null 返回false 说明有多个元素 此时 s.thread != Thread.currentThread() 如果返回true 说明不是重入 肯定要排队 如果返回false 说明是重入的 那么可以尝试cas获取锁 1.2: 如果队列中的元素只有一个，说明最后一个线程加锁了 前面的都已经unlock了 此时 h!=t返回的是 false 那么直接去cas竞争锁","link":"/2022/06/04/%E9%94%81%E5%88%86%E6%9E%90/"},{"title":"IO 流","text":"IO是网络世界中不可获缺的并且很重要的一部分，它是input|output的缩写，有了它，我们才能在网络中传输数据，包括输入和输出 分类 输入流：主要有InputStream 和 Reader这两个字节和字符流 输出流：主要有OutputStream 和 Writer这两个字节和字符流 字节流：可以操作任何数据 字符流：转么用来操作字符的，比较方便 常用的流流的种类很多，我们只需要知道常用的流，知道他们的原理就好，以后用到其他的再去查阅即可 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// FileInputStream/FileReader // FileOutputStream/FileWriterpackage com.hyf.demo.io;import java.io.File;import java.io.FileInputStream;import java.io.FileOutputStream;import java.io.IOException;public class FileInputStreamTest { public static void main(String[] args) { // 将一个文本写入到一个文件 String txt = &quot;hello java&quot;; File file = new File(&quot;/Users/huyunfei/Downloads/java.txt&quot;); try { FileOutputStream fileInputStream = new FileOutputStream(file, true); fileInputStream.write(txt.getBytes()); } catch (IOException e) { e.printStackTrace(); } // 读取路径中的数据 输出到控制台 FileInputStream fileInputStream = null; try { fileInputStream = new FileInputStream(file); // 1. 这种方式是一个一个字节读取 int msg; while ((msg = fileInputStream.read()) != -1) { System.out.println((char) msg); } // 2. 这种方式是1024个字节读取 byte[] bytes = new byte[1024]; while (fileInputStream.read(bytes) != -1) { System.out.println(new String(bytes)); } } catch (IOException e) { e.printStackTrace(); } finally { try { fileInputStream.close(); } catch (IOException e) { e.printStackTrace(); } } }} 这个是最基础的输入输出,还有专门用于读取字符的流 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.hyf.demo.io;import java.io.*;public class BufferReaderTest { public static void main(String[] args) { // 将一个文本写入到一个文件 String txt = &quot;hello buffer\\n&quot;; File file = new File(&quot;/Users/huyunfei/Downloads/java.txt&quot;); try { BufferedOutputStream bufferedOutputStream = new BufferedOutputStream(new FileOutputStream(file)); bufferedOutputStream.write(txt.getBytes()); bufferedOutputStream.flush(); // 字符buffer写入基础代码// BufferedWriter bufferedWriter = new BufferedWriter(new FileWriter(file));// bufferedWriter.write(txt);// bufferedWriter.newLine();// bufferedWriter.flush(); } catch (IOException e) { e.printStackTrace(); } // 读取路径中的数据 输出到控制台 BufferedReader bufferedReader = null; try { bufferedReader = new BufferedReader(new FileReader(file)); // 1. 这种方式是一行一行读取 String msg; while ((msg = bufferedReader.readLine()) != null) { System.out.println(msg); } // 2. 这种方式是1024个字节读取 上面读取完毕后 流里面的数据会清空// char[] bytes = new char[1024];// while (bufferedReader.read(bytes) != -1) {// System.out.println(new String(bytes));// } } catch (IOException e) { e.printStackTrace(); } finally { try { bufferedReader.close(); } catch (IOException e) { e.printStackTrace(); } } }} 上面是按照带buffer的流读取的基础代码 牵扯到的两个问题为什么要出现带缓冲区的流使用带缓冲的流包装基础流涉及到的设计模式 接着我们来解释第一个问题，为什么要使用带缓冲区的流? 一般来说我们进行频繁数据读写的时候，很耗费性能，于是我们需要将需要读写的数据找到一个地方暂存起来，然后进行一个批量的读写，用的也是顺序写，用来缓解不同设备之间频繁的数据读写，于是有了缓冲区的出现 怎么证明使用了buffer 比不使用buffer 速度快呢？ 源码如下 12345678910111213141516171819 public synchronized void write(byte b[], int off, int len) throws IOException { //在这判断需要写的数据长度是否已经超出容器的长度（8192byte）了,如果超出则直接写到相应的outputStream中,并清空缓冲区 if (len &gt;= buf.length) { /* If the request length exceeds the size of the output buffer, flush the output buffer and then write the data directly. In this way buffered streams will cascade harmlessly. */ flushBuffer(); out.write(b, off, len); return; } // 判断缓冲区剩余的容量是否还够写入当前len的内容,如果不够则清空缓冲区 if (len &gt; buf.length - count) { flushBuffer(); } // 将要写的数据先放入内存中,等待数据达到了缓冲区的长度后,再写到相应的outputStream中 System.arraycopy(b, off, buf, count, len); count += len;}// 他不是每次都调用系统的write 而是积攒到8192byte后才调用一次write 大大减少了系统调用 实验如下 123456789101112131415161718192021222324252627282930313233343536373839import java.io.BufferedOutputStream;import java.io.File;import java.io.FileOutputStream;public class OSFileIO { static byte[] data = &quot;123456789\\n&quot;.getBytes(); static String path = &quot;/data/io/out.txt&quot;; public static void main(String[] args) throws Exception { switch (args[0]) { case &quot;0&quot;: testBasicFileIO(); break; case &quot;1&quot;: testBufferedFileIO(); break; default: break; } } public static void testBasicFileIO() throws Exception { File file = new File(path); FileOutputStream out = new FileOutputStream(file); while (true) { out.write(data); } } public static void testBufferedFileIO() throws Exception { File file = new File(path); BufferedOutputStream out = new BufferedOutputStream(new FileOutputStream(file)); while (true) { out.write(data); } }}// 这段代码来源于网络 将这段代码上传到linux目录 1/Users/huyunfei/Documents/study/testCase/io 然后执行 1234# 编译java文件javac OSFileIO.java# 使用strace 分析这个程序涉及到的系统调用strace -ff -o out java OSFileIO $1 可以发现最终的结果是，不使用buffer的流，系统调用的write很多，而使用了buffer的达到了8192 byte才会进行一个系统write调用，所以很明显使用buffer后速度更快 第二个问题 这里涉及到的设计模式是什么 流中涉及到的设计模式最经典的就是装饰者模式，就是在已有类上进行装饰增强。这样做的优点是可以不改变已有的类，比继承灵活，完全遵循开闭原则；缺点是增加了更多的类，多层装饰增加了代码复杂性 其实还有一些常用的流，比如对象流（可以直接传输对象）、还有我们一般对于文件的读写比较多，但是频繁的文件读写并不好，所以我们可以使用字节数组流，也称为内存流， 对象流1234567891011121314151617181920212223242526272829303132333435363738package com.hyf.demo.io;import java.io.*;public class ObjectIOTest { public static void main(String[] args) { try { // 将一个对象序列化到文件中 Student student = new Student(&quot;libei&quot;, 18); FileOutputStream fileOutputStream = new FileOutputStream(&quot;/Users/huyunfei/Downloads/java.txt&quot;); ObjectOutputStream writeObjectStream = new ObjectOutputStream(fileOutputStream); writeObjectStream.writeObject(student); // 将文件中对象反序列化出来 FileInputStream fileInputStream = new FileInputStream(&quot;/Users/huyunfei/Downloads/java.txt&quot;); ObjectInputStream readObjectStream = new ObjectInputStream(fileInputStream); Student student1 = (Student) readObjectStream.readObject(); System.out.println(student1); } catch (IOException | ClassNotFoundException e) { e.printStackTrace(); } }}// 这里一定要实现序列化接口class Student implements Serializable { private String name; private Integer age; public Student(String name, Integer age) { this.name = name; this.age = age; }} 字节数组流1234567891011121314151617181920212223242526package com.hyf.demo.io;import java.io.*;public class ByteArrayInputStreamTest { public static void main(String[] args) { ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream(); DataOutputStream dataOutputStream = new DataOutputStream(byteArrayOutputStream); try { dataOutputStream.writeDouble(Math.random()); dataOutputStream.writeBoolean(true); ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(byteArrayOutputStream.toByteArray()); DataInputStream dataInputStream = new DataInputStream(byteArrayInputStream); System.out.println(dataInputStream.available()); System.out.println(dataInputStream.readBoolean()); System.out.println(dataInputStream.readDouble()); System.out.println(dataInputStream.available()); } catch (IOException e) { e.printStackTrace(); } }} 常用的流就这些，我们在日常工作用到了查手册就好。 选用哪种流 记得刚才我们分析过了有一个BufferOutoutStream为什么快，那它和这个内存流ByteOutputStream有什么区别呢？ ByteOutputStream 会每次创建一个32个byte的buffer，每次写入的时候会对比剩余容量是否够用，如果不够用就grow这个buffer 继续写入，一直等数据写完，这些数据都是在内存的 12345678910public synchronized void write(byte b[], int off, int len) { if ((off &lt; 0) || (off &gt; b.length) || (len &lt; 0) || ((off + len) - b.length &gt; 0)) { throw new IndexOutOfBoundsException(); } // 确保buffer 足够 ensureCapacity(count + len); System.arraycopy(b, off, buf, count, len); count += len; } 所以如果想要快速写入的话，使用ByteArrayOutputStream,如果资源不太够用的时候，应该选择BufferOutputStream 下一篇说一下各种IO的区别和背景，以及网络IO的演进","link":"/2023/05/05/IO/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2022/03/27/hello-world/"}],"tags":[{"name":"java","slug":"java","link":"/tags/java/"},{"name":"IO","slug":"IO","link":"/tags/IO/"}],"categories":[{"name":"java","slug":"java","link":"/categories/java/"},{"name":"hello word","slug":"java/hello-word","link":"/categories/java/hello-word/"},{"name":"锁分析","slug":"java/锁分析","link":"/categories/java/%E9%94%81%E5%88%86%E6%9E%90/"},{"name":"IO","slug":"java/IO","link":"/categories/java/IO/"}],"pages":[{"title":"","text":"五颜六色的生活啊 free time","link":"/album/index.html"},{"title":"","text":"个人简介攻城狮，喜欢听歌看电影读文电台，一个人走夜路 分享老罗说过的的一段话： “每一个生命来到世间都注定改变世界，别无选择。要么变得好一点，要么变得坏一点。你如果走进社会为了生存为了什么不要脸的理由，变成了一个恶心的成年人社会中的一员，那你就把这个世界变得恶心了一点点。如果你一生刚正不阿，如果你一生耿直，没有做任何恶心的事情，没做对别人有害的事情，一辈子拼了老命勉强把自己身边的几个人照顾好了，没有成名没有发财，没有成就伟大的事业，然后耿着脖子一生正直，到了七八十岁耿着脖子去世了。你这一生是不是没有改变世界？你还是改变世界了，你把这个世界变得美好了一点点。因为世界上又多了一个好人。“ 历史书太小，只会记住那些天才但是感谢互联网，这个时代能够记住每一个做出贡献的人这些贡献记录在github上,记录在无时无刻都在流淌的数据里 来到这里的小伙伴们我们一起加油！ 博客信息 网站采用的Icarus主题 追求尽可能的简洁，清晰，易用。 在Icarus主题之上进行了部分修改。","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"","text":"给我留个言吧 留言板加载中，请稍等... $.getScript(\"https://unpkg.com/gitalk/dist/gitalk.min.js\", function () { var gitalk = new Gitalk({ clientID: 'a1ad219ff90da8100007', clientSecret: '97b9266d67d87e37cdcb328e10460af8295a4e7d', id: '2423', repo: 'hxq94.github.io', owner: 'hxq94', admin: \"hxq94\", createIssueManually: true, distractionFreeMode: false }); gitalk.render('comment-container1'); });","link":"/self-talking/index.html"}]}